{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import const\n",
    "import utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading custom train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = sorted(os.listdir(\"./DATASET/IMAGES\"))\n",
    "annotation_paths = sorted(os.listdir(\"./DATASET/ANNOTATIONS\"))\n",
    "\n",
    "# load Image objects\n",
    "IMAGES = []\n",
    "for i in zip(img_paths, annotation_paths):\n",
    "\n",
    "    img_path = f\"./DATASET/IMAGES/{i[0]}\"\n",
    "    annotation_path = f\"./DATASET/ANNOTATIONS/{i[1]}\"\n",
    "\n",
    "    img, boxes, labels = utils.get_image_data(img_path, annotation_path)\n",
    "\n",
    "    preprocessed_img, preprocessed_boxes = utils.preprocess(img, boxes)\n",
    "\n",
    "    IMAGES.append(const.Image(preprocessed_img, preprocessed_boxes, labels))\n",
    "\n",
    "# obtain images, bounding boxes and labels as Tensors\n",
    "IMAGES_TENSOR = [i.get_tensor_image() for i in IMAGES]\n",
    "BOX_TENSOR = [i.get_tensor_image_data()[0] for i in IMAGES]\n",
    "LABEL_TENSOR = [i.get_tensor_image_data()[1] for i in IMAGES]\n",
    "\n",
    "print(f\"Total of {len(IMAGES)} images loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain train and test sets\n",
    "\n",
    "train_images, test_images, train_boxes, test_boxes, train_labels, test_labels = train_test_split(\n",
    "    IMAGES_TENSOR, BOX_TENSOR, LABEL_TENSOR, \n",
    "    test_size=0.1, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom train and test dataset\n",
    "train_dataset = const.CustomDataset(train_images, train_boxes, train_labels)\n",
    "test_dataset = const.CustomDataset(test_images, test_boxes, test_labels)\n",
    "\n",
    "print(f\"Train set : {len(train_dataset.imgs)} images\")\n",
    "print(f\"Test set : {len(test_dataset.imgs)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataLoader for both train and test sets ; provide an iterable for each set\n",
    "def custom_collate(data):\n",
    "    return data\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    #num_workers = 2,\n",
    "    #timeout = 60,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    #num_workers = 2,\n",
    "    #timeout = 60,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising model (Faster R-CNN using ResNet-50 with FPN as backbone model)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = fasterrcnn_resnet50_fpn(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change prediction head to have 3 classes\n",
    "num_classes = 3\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift model to device\n",
    "model.to(device)\n",
    "print(\"Model shifted to device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Stochastic Gradient Descent optimizer\n",
    "# requires_grad = True ; gradients need to be computed for the parameter\n",
    "parameters = [i for i in model.parameters() if i.requires_grad == True]\n",
    "optimizer = SGD(\n",
    "    parameters,\n",
    "    lr=1e-5,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for data in tqdm(train_data_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "\n",
    "        imgs = []\n",
    "        targets = []\n",
    "\n",
    "        for d in data:\n",
    "            imgs.append(d[0].float().to(device))\n",
    "            targets.append({'boxes':d[1]['boxes'].to(device), 'labels':d[1]['labels'].to(device)})\n",
    "\n",
    "        loss_dict = model(imgs, targets)\n",
    "        loss = sum(v for v in loss_dict.values())\n",
    "\n",
    "        epoch_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(\"Model switched to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = iter(test_data_loader).__next__()\n",
    "\n",
    "test_img = test_data[0][0]\n",
    "test_box = test_data[0][1][\"boxes\"]\n",
    "test_label = test_data[0][1][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model([test_img.to(device)])\n",
    "\n",
    "output_box = output[0]['boxes']\n",
    "output_score = output[0]['scores']\n",
    "output_label = output[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = torchvision.ops.nms(output_box, output_score, 0.1)\n",
    "\n",
    "keep_box = output_box[keep].cpu().detach().numpy().astype('int32')\n",
    "keep_label = output_label[keep].cpu().detach().numpy()\n",
    "keep_label_mapped = [const.REVERSE_LABEL_MAPPING[i] for i in keep_label]\n",
    "\n",
    "print(len(keep), \"objects kept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = const.Image(\n",
    "    test_img.permute(1,2,0).cpu().numpy().astype('uint8'),\n",
    "    keep_box, keep_label_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
